package cs237;

import org.apache.log4j.LogManager;
import org.apache.log4j.Logger;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;

import com.google.common.io.Closeables;

import org.apache.spark.storage.StorageLevel;
import org.apache.spark.streaming.Duration;
import org.apache.spark.api.java.function.Function;
import org.apache.spark.streaming.api.java.JavaDStream;
import org.apache.spark.streaming.api.java.JavaPairDStream;
import org.apache.spark.streaming.api.java.JavaReceiverInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;
import org.apache.spark.streaming.receiver.Receiver;
import scala.Tuple2;

import java.io.BufferedReader;
import java.io.InputStreamReader;
import java.net.ConnectException;
import java.net.Socket;
import java.nio.charset.StandardCharsets;
import java.util.regex.Pattern;

public class SparkAppJava extends Receiver<String> {
    // ============= Receiver code that receives data over a socket ==============

    String host = null;
    int port = -1;

    public static Logger log = LogManager.getRootLogger();

    public static void main(String[] args) throws Exception {

        if (args.length < 2) {
            System.err.println("Usage: JavaCustomReceiver <hostname> <port>");
            System.exit(1);
        }

//        Pattern SPACE = Pattern.compile(" ");
        // Create the context with a 5 second batch size
        SparkConf sparkConf = new SparkConf().setAppName("JavaCustomReceiver");
        JavaStreamingContext ssc = new JavaStreamingContext(sparkConf, new Duration(5000));

        // Create an input stream with the custom receiver on target ip:port and count the
        // words in input stream of \n delimited text (eg. generated by 'nc')

        JavaReceiverInputDStream<String> lines = ssc.receiverStream(new SparkAppJava(args[0], Integer.parseInt(args[1])));
//        JavaDStream<String> words = lines.flatMap(x -> Arrays.asList(SPACE.split(x)).iterator());
//        JavaPairDStream<String, Integer> wordCounts = words.mapToPair(s -> new Tuple2<>(s, 1))
//                .reduceByKey((i1, i2) -> i1 + i2);
//
//        wordCounts.print();

        // - DEBUG - //
        lines.print(10);
        log.debug("---------Original Input----------");
        log.debug(lines);
        // - DEBUG - //


        // Filter only data begin with "ThermometerObservation";
        JavaDStream<String> thermometerReadings = lines.filter(
                new Function<String, Boolean>() {
                    public Boolean call(String line) {
                        return "ThermometerObservation".equalsIgnoreCase(line.split("\\|")[0]);
                    }}
        );

        // - DEBUG - //
        thermometerReadings.print(10);
        log.debug("---------Thermometer Readings----------");
        log.debug(thermometerReadings);
        // - DEBUG - //

        // Map the data into <sensorID-timestamp, reading>
        JavaPairDStream<String, Integer> sensorReadings = thermometerReadings.mapToPair(
                s -> {
                    try {
                        String sensorID = s.split("\\|")[4];
                        String timestamp = s.split("\\|")[3];
                        Integer reading = Integer.valueOf(s.split("\\|")[2]);
                        return new Tuple2<>(sensorID + "-" + timestamp, reading);
                    } catch (Exception e) {
                        System.err.println("[mapToPair] Exception data: " + s);
                        return new Tuple2<>("", 0);
                    }
                }
        );

        // - DEBUG - //
        sensorReadings.print(10);
        log.debug("---------Sensor Readings----------");
        log.debug(sensorReadings);
        // - DEBUG - //

        // Filter the data for sensorReadings value >= 80
        JavaPairDStream<String, Integer> output = sensorReadings.filter(reading -> reading._2 >= 80);

        // Output these readings.
        output.print();

        // - DEBUG - //
        log.debug("---------Out put-----------");
        log.debug(output);
        // - DEBUG - //

        ssc.start();
        ssc.awaitTermination();
    }

    public SparkAppJava(String host_ , int port_) {
        super(StorageLevel.MEMORY_AND_DISK_2());
        host = host_;
        port = port_;
    }

    @Override
    public void onStart() {
        // Start the thread that receives data over a connection
        new Thread(this::receive).start();
    }

    @Override
    public void onStop() {
        // There is nothing much to do as the thread calling receive()
        // is designed to stop by itself isStopped() returns false
    }

    /** Create a socket connection and receive data until receiver is stopped */
    private void receive() {
        try {
            Socket socket = null;
            BufferedReader reader = null;
            try {
                // connect to the server
                socket = new Socket(host, port);
                reader = new BufferedReader(
                        new InputStreamReader(socket.getInputStream(), StandardCharsets.UTF_8));
                // Until stopped or connection broken continue reading
                String userInput;
                while (!isStopped() && (userInput = reader.readLine()) != null) {
                    //System.out.println("Received data '" + userInput + "'");
                    //log.debug("---------Original Input-----------");
                    //log.debug(userInput);
                    store(userInput);
                }
            } finally {
                Closeables.close(reader, /* swallowIOException = */ true);
                Closeables.close(socket,  /* swallowIOException = */ true);
            }
            // Restart in an attempt to connect again when server is active again
            restart("Trying to connect again");
        } catch(ConnectException ce) {
            // restart if could not connect to server
            restart("Could not connect", ce);
        } catch(Throwable t) {
            restart("Error receiving data", t);
        }
    }
}
